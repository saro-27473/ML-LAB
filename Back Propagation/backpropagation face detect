import torch
import torch.nn as nn
import torch.optim as optim
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(3*64*64, 256)
        self.fc2 = nn.Linear(256, 2)

    def forward(self, x):
        x = x.view(-1, 3*64*64)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x


net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)


import torch
from torchvision import datasets, transforms
transform = transforms.Compose([transforms.Resize((64,64)),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
trainset = datasets.ImageFolder(root='FACE/train', transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)


for epoch in range(10):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
    print(f"Epoch {epoch + 1}, loss: {running_loss / len(trainloader)}")

print('Finished Training')


classes = trainset.classes
print(classes)


from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
img = Image.open("FACE/test/dhoni/91693052.webp")
plt.imshow(img)
transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
img = transform(img)
img = img.unsqueeze(0)
net.eval()
output = net(img)
_, predicted_class = torch.max(output.data,1)
classes = trainset.classes
print(classes[predicted_class])


from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
img = Image.open("FACE/test/abdulkalam/images.jpg")
plt.imshow(img)
transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
img = transform(img)
img = img.unsqueeze(0)
net.eval()
output = net(img)
_, predicted_class = torch.max(output.data,1)
classes = trainset.classes
print(classes[predicted_class])
